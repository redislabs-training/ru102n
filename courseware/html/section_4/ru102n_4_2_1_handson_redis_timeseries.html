<h1>Hands-On with Redis Time Series</h1>

<p>
    In this Hands-On we'll be exploring how to use the Time Series data structure in Redis using NRedisTimeSeries.
    You can either create your own project to follow along with and connect a multiplexer,
    or you can open <span style="font-family: 'courier new', courier;">/src/section_4/section4.2/section4.2.csproj</span> in your IDE.
</p>

<h2>Connecting to Redis</h2>

<p>
    NRedisTimeSeries is an extension of StackExchange.Redis, consequentially connecting to Redis is exactly the same with NRedisTimeSeries 
    as with StackExchange.Redis. The key difference, is that at the top of your <span style="font-family: 'courier new', courier;"><i>Program.cs</i></span> file, you need to add a few imports to
    use the NRedisTimeSeries bits:
</p>

<pre>
<code>
    using NRedisTimeSeries;
    using NRedisTimeSeries.Commands.Enums;
    using NRedisTimeSeries.DataTypes;
</code>
</pre>

<p>
    NRedisTimeSeries is built as static extensions to IDatabase, so after you've gotten a handle to your IDatabase, you'll be able to execute
    whatever you like against the Time Series Data Structure.
</p>

<h2>Create Time Series and Compaction Rules</h2>

<p>
    A Time Series is a time-tagged sequence of numbers that flow into the same key. For our example here, we'll be working with a very simple
    Time Series <span style="font-family: 'courier new', courier;"><i>sensor</i></span>. We'll have a producer task to add random data to the Time Series continually, we'll then have compaction 
    rules that will find the average, min, and max that occurred in the Time Series during a given interval. First we'll create the Time Series.
</p>

<pre>
<code>
    await db.TimeSeriesCreateAsync("sensor", 60000, new List<TimeSeriesLabel>{new TimeSeriesLabel("id", "sensor-1")});
</code>
</pre>

<p>
    With the Time Series created, we'll then identify the three aggregations we want to run. We'll create a Time Series for each of our
    compactions, those Time Series will carry a label with them so that we can filter on that label later when we run our query.
</p>
<p>
    After the Time Series are created, we'll then bind a rule to our primary Time Series, to run the compaction into the relevant Time Series. To do that
    we just need to call <span style="font-family: 'courier new', courier;">TimeSeriesCreate</span> and <span style="font-family: 'courier new', courier;">TimeSeriesCreateRule</span> for each rule we want to create:
</p>

<pre>
<code>
    var aggregations = new TsAggregation[]{TsAggregation.Avg, TsAggregation.Min, TsAggregation.Max};
    foreach(var agg in aggregations)
    {
        await db.TimeSeriesCreateAsync($"sensor:{agg}", 60000, new List&lt;TimeSeriesLabel&gt;{new ("type", agg.ToString()), new("aggregation-for", "sensor-1")});
        await(db.TimeSeriesCreateRuleAsync("sensor", new TimeSeriesRule($"sensor:{agg}", 5000, agg)));
    }
</code>
</pre>

<h2>Produce Time Series Data</h2>

<p>
    Time Series Data can consisted of any time-tagged numeric data, this can be anything from sensor temperature readings, to live stock prices 
    from a stock exchange, to radio signals. In our example, we're going to have a producer task which produces a simple random integer every
    second. 
</p>
<p>
    To do this, all you need to do is use the <span style="font-family: 'courier new', courier;">TimeSeriesAdd</span> method, you can either pass in a <span style="font-family: 'courier new', courier;">Timestamp</span>
    or you can just pass in the string "<span style="font-family: 'courier new', courier;"><i>*</i></span>" - which will create the millisecond timestamp based on when the data reached Redis.
</p>

<pre>
<code>
    var producerTask = Task.Run(async()=>{
        while(true)
        {
            await db.TimeSeriesAddAsync("sensor", "*", Random.Shared.Next(50));
            await Task.Delay(1000);
        }
    });
</code>
</pre>

<h2>Primary Consumer</h2>

<p>
    Because we have the primary Time Series, and the extra compaction Time Series running in parallel, we will have two consumer tasks. The first
    of these will use <span style="font-family: 'courier new', courier;">TimeSeriesGet</span> every second, to retrieve the most recent data from the Time Series.
</p>

<pre>
<code>
    var consumerTask = Task.Run(async()=>{
        while(true)
        {
            await Task.Delay(1000);
            var result = await db.TimeSeriesGetAsync("sensor");
            Console.WriteLine($"{result.Time.Value}: {result.Val}");
        }
    });
</code>
</pre>

<h2>Aggregation Consumer</h2>

<p>
    The second Consumer will retrieve the aggregated data across our compacted Time Series. This will run every 5 seconds to coincide with
    our compaction rules. In this case we'll use <span style="font-family: 'courier new', courier;">TimeSeriesMGet</span>. In this case however we'll be using the label that we created earlier
    to query multiple Time Series with the relevant label.
</p>

<pre>
<code>
    var aggregationConsumerTask = Task.Run(async()=>
    {
        while(true)
        {
            await Task.Delay(5000);
            var results = await db.TimeSeriesMGetAsync(new List&lt;string&gt;(){"aggregation-for=sensor-1"}, true);
            foreach(var result in results)
            {
                Console.WriteLine($"{result.labels.First(x=>x.Key == "type").Value}: {result.value.Val}");
            }

        }
    });
</code>
</pre>

<h2>Add a ReadKey and Run</h2>

<p>
    The last thing we need to do for this sample is to add a <span style="font-family: 'courier new', courier;">Console.ReadKey()</span> at the bottom of our file. This will
    cause the tasks we spun up earlier to run endlessly until you press any key to exit. To run the example, just use <span style="font-family: 'courier new', courier;">dotnet run</span>
    from your terminal.
</p>